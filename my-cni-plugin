#!/bin/bash

# TODO:
# Tasks of the CNI plugin:
# 0. Create bridge in default netns
# 1. Create network interface in Pod namespace and assign it an IP address => DONE
# 2. Ensure the following types of connectivity (all types include vice versa direction)
#    1. Pod <=> agent on node                 : Pod => node (bridge is default gateway for Pods), node => Pod (default route created in default namespace)
#    2. Pod ot other Pod on same node         : Needs FORWARD ACCEPT rules in iptables of default netns (packets: Pod netns => bridge in default netns => Pod netns)
#    3. Pod to other Pod on different node    : Needs route in default netns (from bridge to other node)
#    4. Pod to destinations outside cluster   : Needs NAT in the default netns (IP Masquerade)
# 
# It seems that the bridge plugin (which this plugin tries to imitate) also specifically includes items 0, 2.2, and 2.4 (1 and 2.1 are obvious, not sure about 2.3).
# This means, the bridge plugin also creates the bridge if it doesn't exist and sets up NAT and iptable rules.
# => Add this to this CNI plugin: a section that checks if a given setting already exists and implements it, if it doesn't.
#
# NAT vs IP Masquerade: 
#   IP Masquerade is one type (and the most common type) of NAT. So much that when we speak of NAT, we actually mean IP Masquerade.
#   https://www.dslreports.com/forum/r31309035-IP-Masquerade-vs-NAT

# ADD in bridge plugin:
# - Creates a bridge if it doesn't exist ('ip link add cni0 type bridge', 'ip link set cni0 up'): setupBridge(), ensureBridge()
# - Creates veth pair, moves one end to host netns other to Pod netns, enables both devices: setupVeth()
# - Call IPAM plugin with identical argumnets (env vars and NetConf), save result
# - Add 'routes' field to IPAM response with default route to bridge: calcGateways()
# - Add IP address from IPAM result to Pod-end of veth pair: ConfigureIface() (github.com/containernetworking/plugins/pkg/ipam)
# - Create routes that was added to IPAM response in Pod netns (default route to bridge): ConfigureIface() (github.com/containernetworking/plugins/pkg/ipam) => solves 2.1
# - Add IP address to bridge: ensureAddr()
# - Set the hardware address of the bridge: ensureAddr()
# - Enable IP forwarding (write "1" into /proc/sys/net/ipv4/ip_forward): enableIPForward()
# - Install iptables rules: setupIPMasq() (github.com/containernetworking/plugins/pkg/ip)
#   - POSTROUTING chain in "nat" table: ACCEPT packets from Pod network (on this host) to Pod network (on this host) => solves 2.2
#   - POSTROUTING chain in "nat" table: MASQUERADE packets from Pod network (on this host) to anywhere (except multicast address 224.0.0.0/4) => solves 2.4

# bridge plugin:
# - 'interfaces' field of result includes 'name' and 'mac' (https://github.com/containernetworking/plugins/blob/655116585396cc26ca973db2d5daef66d821ad90/plugins/main/bridge/bridge.go#L346)
# - 'interfaces' field of result includes all three interfaces: Pod-end of veth pair, host-end of veth pair, and bridge
# - 'ips' and 'routes' field or result is directly taken from IPAM result

# TODO:
#   - Create bridge if it doesn't exist (assign it an IP address)
#   - Create iptable rules in default netns, if they don't exist yet:
#     - Allow communication between Pods on same node and between Pods on different nodes
#         iptables -A FORWARD -s <PodCIDR> -j ACCEPT
#         iptables -A FORWARD -s <PodCIDR> -j ACCEPT
#       The PodCIDR must be of the whole Pod network, not only of the subnet for this node
#     - Set up NAT
#         iptables -t nat -A POSTROUTING -s <PodCIDR> ! -o <BridgeName> -j MASQUERADE
#       The PodCIDR must be of the subnet of this node only
#       Explanation about !: traffic coming from PodCIDR and destined for the bridge
#       if from one pod to another pod on the same node. There should be no NAT
#       Question: shouldn't there also be an exception fro traffic comfing from
#       PodCIDR and going to the Pod network in general (including anothe node)?
#
# What the plugin can't do (but the plugin should actually do this):
# Create GCP routes for each host for the PodCIDRs of each other host (to this host)

# Parameters
bridge_name=cni0
setup_done=/var/lib/cni/setup_done

# Read NetConf
netconf=$(cat /dev/stdin)
# Example NetConf:
# {
#   "cniVersion": "0.3.1",
#   "name": "my-pod-network",
#   "type": "my-cni-plugin",
#   "myPodNet": "200.200.0.0/16",
#   "myPodNodeSubnet": "200.200.1.0/24"
# }

# Log the entire input for this plugin invocation
cat <<EOF
CNI_COMMAND=$CNI_COMMAND
CNI_CONTAINERID=$CNI_CONTAINERID
CNI_NETNS=$CNI_NETNS
CNI_IFNAME=$CNI_IFNAME
CNI_PATH=$CNI_PATH
$netconf
EOF

# Extract values from NetConf
pod_net=$(jq -r ".myPodNet" <<<"$netconf")
pod_node_subnet=$(jq -r ".myPodNodeSubnet" <<<"$netconf")

# One-time setup
setup() {
  # 1. Create bridge if it doesn't exist
  ip link add "$bridge_name" type bridge
  ip link set "$bridge_name" up
  ip address add "$bridge_ip"/"${pod_node_subnet#*/}" dev "$bridge_name"

  # 2.Allow forwarding packets between Pods through bridge
  iptables -A FORWARD -s "$pod_net" -j ACCEPT
  iptables -A FORWARD -d "$pod_net" -j ACCEPT

  # 3. Set up NAT
  iptables -t nat -A POSTROUTING -s "$pod_node_subnet" ! -o "$bridge_name" -j MASQUERADE

  # 4. Set up routes between nodes for Pod subnets?????

  # Mark one-time setup as being done
  mkdir -p $(dirname "$setup_done")
  touch "$setup_done"
}

# Create NetConf copy with added 'ipam' field for the host-local IPAM plugin
ipam_netconf=$(jq ". += {
  ipam: {
    subnet: \"$pod_node_subnet\",
    gateway: \"$bridge_ip\"
  }
}" <<<"$netconf")

case "$CNI_COMMAND" in

  # Invoked by kubelet during Pod creation (after creating a netns for the Pod)
  ADD)

    # Do one-time setup if this is the first invocation of the plugin
    [[ ! -f "$setup_done" ]] && setup

    # Invoke host-local IPAM plugin
    ipam_response=$(/opt/cni/bin/host-local <<<"$ipam_netconf")
    # Example host-local response:
    # {
    #   "cniVersion": "0.3.1",
    #   "ips": [
    #     {
    #       "version": "4",
    #       "address": "20.0.0.4/24",
    #       "gateway": "20.0.0.1"
    #     }
    #   ],
    #   "dns": {}
    # }

    # Pod IP address selected by IPAM plugin
    pod_ip=$(jq -r '.ips[0].address' <<<"$ipam_response")

    # Make the Pod netns discoverable by 'ip' as $CNI_CONTAINERID
    mkdir -p /var/run/netns/ && ln -s "$CNI_NETNS" /var/run/netns/"$CNI_CONTAINERID"

    # Name of host-end of the veth pair (name of the Pod-end is $CNI_IFNAME)
    host_ifname=veth$RANDOM

    # Default netns: create new veth pair
    ip link add "$CNI_IFNAME" type veth peer name "$host_ifname"

    # Default netns: enable host-end of the pair and add it to the bridge
    ip link set "$host_ifname" up master "$bridge_name"

    # Default netns: enable Pod-end of the pair and put it into the Pod netns
    ip link set "$CNI_IFNAME" up netns "$CNI_CONTAINERID"
    
    # Pod netns: add a default route to the bridge via the Pod-end of the pair
    ip netns exec "$CNI_CONTAINERID" ip route add default via "$bridge_ip" dev "$CNI_IFNAME"

    # Pod netns: assign the selected IP address to the Pod-end of the pair
    ip netns exec "$CNI_CONTAINERID" ip addr add "$pod_ip" "$CNI_IFNAME"

    # Write response by adding 'interfaces' field to IPAM plugin response
    jq ". += {
          interfaces: [
            {
              name: \"$CNI_IFNAME\",
              sandbox: \"$CNI_NETNS\"
            }
          ]
        } |
        .ips[0] += {
          interface: 0
        }" <<<"$ipam_response"
    ;;

  # Invoked by kubelet during Pod deletion (before deleting the Pod's netns).
  # Note: since the kubelet will delete the entire network namespace, it is not
  # necessary to delete the network resources that were created by ADD because
  # they will be automatically deleted when the network namespace is deleted.
  DEL)
    # Invoke host-local IPAM plugin to un-reserve the Pod's IP address
    /opt/cni/bin/host-local <<<"$ipam_netconf"
    ;;

  # Return implemented and supported versions of CNI specification
  VERSION)
    echo '{"cniVersion":"0.3.1","supportedVersions":["0.1.0","0.2.0","0.3.0","0.3.1"]}'
    ;;
esac
